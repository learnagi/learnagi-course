---
title: "è¯­éŸ³è½¬æ–‡æœ¬"
slug: "speech-to-text"
sequence: 5
description: "å­¦ä¹ ä½¿ç”¨OpenAIçš„Whisperæ¨¡å‹å°†è¯­éŸ³è½¬æ¢ä¸ºæ–‡æœ¬ï¼ŒæŒæ¡éŸ³é¢‘è½¬å½•å’Œç¿»è¯‘çš„æŠ€å·§"
is_published: true
estimated_minutes: 25
language: "zh-CN"
updated_at: "2024-01-26"
---

![Header Image](https://z1.zve.cn/tutorial/llm-basics/speech-to-text_header.png)
*è®©AIå€¾å¬ä½ çš„å£°éŸ³*

# è¯­éŸ³è½¬æ–‡æœ¬

## æœ¬èŠ‚æ¦‚è¦

é€šè¿‡æœ¬èŠ‚å­¦ä¹ ï¼Œä½ å°†å­¦ä¼šï¼š
- ä½¿ç”¨OpenAIçš„Whisper APIå°†è¯­éŸ³è½¬æ¢ä¸ºæ–‡æœ¬
- æŒæ¡éŸ³é¢‘è½¬å½•å’Œç¿»è¯‘çš„å…³é”®æŠ€æœ¯
- å¤„ç†é•¿éŸ³é¢‘å’Œä¼˜åŒ–è½¬å½•è´¨é‡
- å®ç°å¤šè¯­è¨€éŸ³é¢‘å¤„ç†

ğŸ’¡ é‡ç‚¹å†…å®¹ï¼š
- Whisper APIçš„åŸºæœ¬ç”¨æ³•
- éŸ³é¢‘è½¬å½•å’Œç¿»è¯‘çš„åŒºåˆ«
- æ—¶é—´æˆ³å’Œå­—å¹•ç”Ÿæˆ
- æç¤ºè¯ä¼˜åŒ–æŠ€å·§

## 1. åŸºç¡€æ¦‚å¿µ

### 1.1 è¯­éŸ³è½¬æ–‡æœ¬ç®€ä»‹
è¯­éŸ³è½¬æ–‡æœ¬ï¼ˆSpeech-to-Textï¼ŒSTTï¼‰æ˜¯å°†å£è¯­éŸ³é¢‘è½¬æ¢ä¸ºä¹¦é¢æ–‡æœ¬çš„æŠ€æœ¯ã€‚OpenAIçš„éŸ³é¢‘è½¬æ–‡æœ¬APIåŸºäºå¼€æºçš„Whisper large-v2æ¨¡å‹ï¼Œæä¾›ä¸¤ä¸ªä¸»è¦åŠŸèƒ½ï¼š
1. **è½¬å½•ï¼ˆTranscriptionsï¼‰**ï¼šå°†éŸ³é¢‘è½¬æ¢ä¸ºåŸå§‹è¯­è¨€çš„æ–‡æœ¬
2. **ç¿»è¯‘ï¼ˆTranslationsï¼‰**ï¼šå°†éŸ³é¢‘ç›´æ¥è½¬æ¢ä¸ºè‹±æ–‡æ–‡æœ¬

### 1.2 æ”¯æŒçš„æ ¼å¼
ç›®å‰æ”¯æŒçš„éŸ³é¢‘æ ¼å¼åŒ…æ‹¬ï¼š
- mp3, mp4, mpeg, mpga, m4a, wav, webm
- æ–‡ä»¶å¤§å°é™åˆ¶ï¼š25 MB

## 2. åŸºç¡€åŠŸèƒ½

### 2.1 ç¯å¢ƒå‡†å¤‡
é¦–å…ˆï¼Œå®‰è£…å¿…è¦çš„ä¾èµ–ï¼š

```bash
pip install openai python-dotenv
```

### 2.2 åŸºç¡€ç¤ºä¾‹
è®©æˆ‘ä»¬ä»ä¸€ä¸ªç®€å•çš„éŸ³é¢‘è½¬å½•ç¤ºä¾‹å¼€å§‹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸Šä¸€ç« ç”Ÿæˆçš„è¯­éŸ³æ–‡ä»¶ä½œä¸ºè¾“å…¥ï¼š

> ğŸ”Š [ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶](https://z1.zve.cn/tutorial/llm-basics/test_speech.mp3)

```python
from pathlib import Path
import os
from openai import OpenAI
from dotenv import load_dotenv

def transcribe_audio(input_file, prompt=None):
    """è½¬å½•éŸ³é¢‘æ–‡ä»¶ä¸ºæ–‡æœ¬
    
    Args:
        input_file (str): è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        prompt (str, optional): æç¤ºè¯ï¼Œå¸®åŠ©æé«˜è¯†åˆ«å‡†ç¡®ç‡
        
    Returns:
        dict: è½¬å½•ç»“æœï¼ŒåŒ…å«æ–‡æœ¬å’Œè¯¦ç»†ä¿¡æ¯
    """
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = OpenAI()
    
    # æ‰“å¼€éŸ³é¢‘æ–‡ä»¶
    with open(input_file, "rb") as audio_file:
        try:
            # è°ƒç”¨APIè½¬å½•éŸ³é¢‘
            transcription = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="verbose_json",  # è·å–è¯¦ç»†ä¿¡æ¯
                timestamp_granularities=["word"]  # è·å–è¯çº§åˆ«æ—¶é—´æˆ³
            )
            return transcription
            
        except Exception as e:
            print(f"è½¬å½•å¤±è´¥ï¼š{str(e)}")
            return None

# ä½¿ç”¨ç¤ºä¾‹
audio_file = "test_audio.mp3"
result = transcribe_audio(audio_file)
if result:
    print("è½¬å½•æ–‡æœ¬ï¼š", result.text)
    print("è¯­è¨€ï¼š", result.language)
    print("æŒç»­æ—¶é—´ï¼š", result.duration, "ç§’")
```

### 2.3 éŸ³é¢‘ç¿»è¯‘
å°†éè‹±è¯­éŸ³é¢‘ç›´æ¥ç¿»è¯‘ä¸ºè‹±æ–‡ï¼š

```python
def translate_audio(input_file):
    """å°†éŸ³é¢‘ç¿»è¯‘ä¸ºè‹±æ–‡
    
    Args:
        input_file (str): è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        
    Returns:
        str: è‹±æ–‡ç¿»è¯‘ç»“æœ
    """
    client = OpenAI()
    
    with open(input_file, "rb") as audio_file:
        try:
            translation = client.audio.translations.create(
                model="whisper-1",
                file=audio_file,
                response_format="text"
            )
            return translation
            
        except Exception as e:
            print(f"ç¿»è¯‘å¤±è´¥ï¼š{str(e)}")
            return None

# ä½¿ç”¨ç¤ºä¾‹
chinese_audio = "chinese_speech.mp3"
english_text = translate_audio(chinese_audio)
print("è‹±æ–‡ç¿»è¯‘ï¼š", english_text)
```

## 3. é«˜çº§åŠŸèƒ½

### 3.1 æ—¶é—´æˆ³ç”Ÿæˆ
è·å–è¯çº§åˆ«çš„æ—¶é—´æˆ³ï¼Œæ–¹ä¾¿ç”Ÿæˆå­—å¹•ï¼š

```python
def get_word_timestamps(audio_file):
    """è·å–è¯çº§åˆ«çš„æ—¶é—´æˆ³
    
    Args:
        audio_file (str): éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        
    Returns:
        list: åŒ…å«æ¯ä¸ªè¯çš„æ—¶é—´æˆ³ä¿¡æ¯
    """
    result = transcribe_audio(audio_file)
    if not result:
        return []
        
    timestamps = []
    for word in result.words:
        timestamps.append({
            'word': word.word,
            'start': word.start,
            'end': word.end
        })
    return timestamps
```

### 3.2 æç¤ºè¯ä¼˜åŒ–
ä½¿ç”¨æç¤ºè¯æé«˜ç‰¹å®šåœºæ™¯çš„å‡†ç¡®ç‡ï¼š

```python
# åŒ»ç–—é¢†åŸŸç¤ºä¾‹
medical_prompt = """
è¿™æ˜¯ä¸€æ®µåŒ»ç–—ç›¸å…³çš„éŸ³é¢‘ï¼ŒåŒ…å«ä»¥ä¸‹ä¸“ä¸šæœ¯è¯­ï¼š
- é«˜è¡€å‹ (Hypertension)
- å¿ƒå¾‹å¤±å¸¸ (Arrhythmia)
- å† çŠ¶åŠ¨è„‰ç–¾ç—… (Coronary Artery Disease)
"""

result = transcribe_audio(
    "medical_audio.mp3",
    prompt=medical_prompt
)
```

### 3.3 é•¿éŸ³é¢‘å¤„ç†
ä½¿ç”¨PyDubå¤„ç†è¶…è¿‡25MBçš„éŸ³é¢‘ï¼š

```python
from pydub import AudioSegment

def process_long_audio(input_file, segment_duration=600000):
    """å¤„ç†é•¿éŸ³é¢‘æ–‡ä»¶
    
    Args:
        input_file (str): è¾“å…¥éŸ³é¢‘æ–‡ä»¶
        segment_duration (int): åˆ†æ®µæ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    """
    # åŠ è½½éŸ³é¢‘
    audio = AudioSegment.from_mp3(input_file)
    
    # åˆ†æ®µå¤„ç†
    segments = []
    for i in range(0, len(audio), segment_duration):
        segment = audio[i:i+segment_duration]
        segment_path = f"segment_{i//segment_duration}.mp3"
        segment.export(segment_path, format="mp3")
        segments.append(segment_path)
    
    # è½¬å½•æ¯ä¸ªç‰‡æ®µ
    full_text = []
    for segment_path in segments:
        result = transcribe_audio(segment_path)
        if result:
            full_text.append(result.text)
    
    return "\n".join(full_text)
```

## 4. æœ€ä½³å®è·µ

### 4.1 éŸ³é¢‘é¢„å¤„ç†
1. **è´¨é‡ä¼˜åŒ–**ï¼š
   - é™ä½èƒŒæ™¯å™ªéŸ³
   - æé«˜éŸ³é¢‘æ¸…æ™°åº¦
   - è°ƒæ•´é‡‡æ ·ç‡å’Œæ¯”ç‰¹ç‡

2. **æ ¼å¼è½¬æ¢**ï¼š
   - é€‰æ‹©æœ€ä½³æ ¼å¼
   - å‹ç¼©å¤§æ–‡ä»¶
   - ä¿æŒéŸ³è´¨å¹³è¡¡

### 4.2 å‡†ç¡®ç‡æå‡
1. **æç¤ºè¯è®¾è®¡**ï¼š
   - æä¾›é¢†åŸŸæœ¯è¯­
   - è¯´æ˜éŸ³é¢‘ä¸Šä¸‹æ–‡
   - æŒ‡å®šè¾“å‡ºæ ¼å¼

2. **åˆ†æ®µç­–ç•¥**ï¼š
   - æŒ‰è‡ªç„¶åœé¡¿åˆ†æ®µ
   - é¿å…å¥å­ä¸­æ–­
   - ä¿æŒä¸Šä¸‹æ–‡è¿è´¯

### 4.3 åå¤„ç†ä¼˜åŒ–
1. **æ–‡æœ¬æ¸…ç†**ï¼š
   - ä¿®æ­£æ ‡ç‚¹ç¬¦å·
   - æ ¼å¼åŒ–æ®µè½
   - ç»Ÿä¸€æœ¯è¯­ç”¨æ³•

2. **è´¨é‡æ£€æŸ¥**ï¼š
   - äººå·¥æ ¡å¯¹å…³é”®å†…å®¹
   - éªŒè¯ä¸“ä¸šæœ¯è¯­
   - ä¿æŒè¯­è¨€ä¸€è‡´æ€§

## 5. æ‰©å±•èµ„æº

### 5.1 ç›¸å…³æ–‡æ¡£
- [OpenAI Whisper APIæ–‡æ¡£](https://platform.openai.com/docs/guides/speech-to-text)
- [Whisperæ¨¡å‹è®ºæ–‡](https://arxiv.org/abs/2212.04356)
- [éŸ³é¢‘å¤„ç†æœ€ä½³å®è·µ](https://platform.openai.com/docs/guides/speech-to-text/transcriptions-and-translations)

### 5.2 ç¤ºä¾‹ä»£ç 
å®Œæ•´çš„ç¤ºä¾‹ä»£ç å¯ä»¥åœ¨ [GitHubä»“åº“](examples/) ä¸­æ‰¾åˆ°ã€‚

### 5.3 å¸¸è§é—®é¢˜
1. **å¦‚ä½•æé«˜å‡†ç¡®ç‡ï¼Ÿ**
   - ä½¿ç”¨é«˜è´¨é‡éŸ³é¢‘
   - æä¾›å‡†ç¡®çš„æç¤ºè¯
   - é€‰æ‹©åˆé€‚çš„åˆ†æ®µç­–ç•¥

2. **å¦‚ä½•å¤„ç†å¤šè¯­è¨€ï¼Ÿ**
   - ä½¿ç”¨è¯­è¨€æ£€æµ‹
   - é€‰æ‹©åˆé€‚çš„API
   - å¤„ç†ä»£ç åˆ‡æ¢

3. **å¦‚ä½•ä¼˜åŒ–æ€§èƒ½ï¼Ÿ**
   - å®ç°å¹¶è¡Œå¤„ç†
   - ä½¿ç”¨ç¼“å­˜ç­–ç•¥
   - ä¼˜åŒ–æ–‡ä»¶å¤§å°

## å°ç»“

æœ¬èŠ‚æˆ‘ä»¬å­¦ä¹ äº†ï¼š
1. ä½¿ç”¨Whisper APIè¿›è¡ŒéŸ³é¢‘è½¬å½•å’Œç¿»è¯‘
2. å¤„ç†é•¿éŸ³é¢‘å’Œç”Ÿæˆæ—¶é—´æˆ³
3. ä¼˜åŒ–è½¬å½•å‡†ç¡®ç‡å’Œæ€§èƒ½
4. å®ç°å¤šè¯­è¨€éŸ³é¢‘å¤„ç†

ä¸‹ä¸€æ­¥ï¼Œä½ å¯ä»¥ï¼š
- å°è¯•ä¸åŒç±»å‹çš„éŸ³é¢‘è½¬å½•
- æ„å»ºè‡ªåŠ¨å­—å¹•ç”Ÿæˆç³»ç»Ÿ
- å¼€å‘å¤šè¯­è¨€éŸ³é¢‘å¤„ç†åº”ç”¨
