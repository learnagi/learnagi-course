---
title: "æ–‡æœ¬ç”Ÿæˆï¼šLLMçš„æ ¸å¿ƒèƒ½åŠ›"
slug: "text-generation"
sequence: 3.2
description: "æ·±å…¥äº†è§£å¤§è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ï¼ŒæŒæ¡å¯¹è¯å’Œåˆ›ä½œçš„æŠ€å·§"
is_published: false
estimated_minutes: 40
language: "zh-CN"
status: "draft"
created_at: "2024-03-19"
updated_at: "2024-03-19"
---

![æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›](./images/text-generation.png)
*æ¢ç´¢AIçš„è¯­è¨€åˆ›ä½œèƒ½åŠ›*

# æ–‡æœ¬ç”Ÿæˆï¼šLLMçš„æ ¸å¿ƒèƒ½åŠ›

åœ¨è¿™ä¸ªæ¨¡å—ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ã€‚é€šè¿‡æœ¬èŠ‚çš„å­¦ä¹ ï¼Œä½ å°†äº†è§£å¦‚ä½•åˆ©ç”¨OpenAIçš„APIè¿›è¡Œæ–‡æœ¬ç”Ÿæˆï¼Œå¹¶æŒæ¡ä¼˜åŒ–ç”Ÿæˆæ•ˆæœçš„æŠ€å·§ã€‚æˆ‘ä»¬å°†ä»åŸºç¡€æ¦‚å¿µå¼€å§‹ï¼Œé€æ­¥æ·±å…¥åˆ°é«˜çº§åº”ç”¨ã€‚

## æœ¬èŠ‚ä½ å°†å­¦åˆ°

- ç†è§£æ–‡æœ¬ç”Ÿæˆçš„åŸºæœ¬åŸç†
- æŒæ¡OpenAI APIçš„ä½¿ç”¨æ–¹æ³•
- å­¦ä¼šä¼˜åŒ–ç”Ÿæˆæ•ˆæœ
- æ„å»ºå®ç”¨çš„æ–‡æœ¬ç”Ÿæˆåº”ç”¨

ğŸ’¡ é‡ç‚¹å†…å®¹ï¼š
- å¿«é€Ÿå…¥é—¨æ–‡æœ¬ç”Ÿæˆ
- é€‰æ‹©åˆé€‚çš„æ¨¡å‹
- æ„å»ºæœ‰æ•ˆçš„æç¤ºè¯
- ç®¡ç†å¯¹è¯ä¸Šä¸‹æ–‡

## åˆå­¦è€…æŒ‡å—ï¼šæ–‡æœ¬ç”Ÿæˆæ¦‚å¿µ

æ–‡æœ¬ç”Ÿæˆæ˜¯æŒ‡è®¡ç®—æœºæ ¹æ®è¾“å…¥çš„æç¤ºæˆ–é—®é¢˜ï¼Œè‡ªåŠ¨ç”Ÿæˆç±»ä¼¼äººç±»ä¹¦å†™çš„æ–‡å­—ã€‚è¿™å¯ä»¥åŒ…æ‹¬å†™è¯—ã€å›ç­”é—®é¢˜ã€ç”Ÿæˆä»£ç ç­‰ã€‚å¯ä»¥å°†æ–‡æœ¬ç”Ÿæˆæ¯”ä½œä¸€ä¸ªè™šæ‹Ÿçš„å†™ä½œåŠ©æ‰‹ï¼Œä½ ç»™å®ƒä¸€ä¸ªä¸»é¢˜æˆ–é—®é¢˜ï¼Œå®ƒä¼šæ ¹æ®å…¶å­¦ä¹ è¿‡çš„çŸ¥è¯†æ¥åˆ›ä½œå†…å®¹ã€‚

### åˆ†æ­¥è®²è§£

- **æ­¥éª¤1**ï¼šè¾“å…¥æç¤ºâ€”â€”å°±åƒä½ é—®æœ‹å‹ä¸€ä¸ªé—®é¢˜ã€‚
- **æ­¥éª¤2**ï¼šæ¨¡å‹å¤„ç†â€”â€”è®¡ç®—æœºâ€œæ€è€ƒâ€å¦‚ä½•å›ç­”ã€‚
- **æ­¥éª¤3**ï¼šè¾“å‡ºç»“æœâ€”â€”è®¡ç®—æœºç»™å‡ºä¸€ä¸ªå®Œæ•´çš„å›ç­”æˆ–åˆ›ä½œã€‚

### ä½¿ç”¨å®ä¾‹

ä¸¾ä¾‹è¯´æ˜ï¼Œæ¯”å¦‚ä½ è¾“å…¥â€œå†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—â€ï¼Œæ¨¡å‹å¯èƒ½ä¼šç”Ÿæˆä¸€æ®µæè¿°æ˜¥å¤©æ™¯è‰²çš„æ–‡å­—ã€‚

### å¸¸è§é—®é¢˜è§£ç­”

è§£é‡Šä¸€äº›å¸¸è§çš„ç–‘é—®ï¼Œæ¯”å¦‚â€œè®¡ç®—æœºå¦‚ä½•çŸ¥é“æ€ä¹ˆå›ç­”ï¼Ÿâ€â€”â€”æ¨¡å‹é€šè¿‡å¤§é‡çš„æ–‡æœ¬æ•°æ®å­¦ä¹ è¯­è¨€æ¨¡å¼ã€‚

### å›¾ç¤ºè¾…åŠ©

ä½¿ç”¨ç®€å•çš„å›¾è¡¨å±•ç¤ºè¾“å…¥ã€å¤„ç†å’Œè¾“å‡ºçš„è¿‡ç¨‹ï¼Œè®©åˆå­¦è€…æ›´ç›´è§‚åœ°ç†è§£ã€‚

```mermaid
graph LR
A[è¾“å…¥æç¤º] --> B[æ¨¡å‹å¤„ç†]
B --> C[è¾“å‡ºç»“æœ]
```

### äº’åŠ¨ç»ƒä¹ 

æä¾›ä¸€äº›ç®€å•çš„ç»ƒä¹ ï¼Œæ¯”å¦‚è¾“å…¥ä¸€ä¸ªé—®é¢˜ï¼Œç„¶åè§‚å¯Ÿæ¨¡å‹ç”Ÿæˆçš„å›ç­”ï¼Œå¸®åŠ©ä»–ä»¬ç†è§£ç”Ÿæˆè¿‡ç¨‹ã€‚

## å¿«é€Ÿå…¥é—¨

åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä¸€ä¸ªç®€å•çš„Pythonä»£ç ç¤ºä¾‹ï¼Œä»‹ç»å¦‚ä½•ä½¿ç”¨OpenAI APIè¿›è¡ŒåŸºç¡€çš„æ–‡æœ¬ç”Ÿæˆã€‚ä½ å°†å­¦ä¼šå¦‚ä½•åˆå§‹åŒ–å®¢æˆ·ç«¯å¹¶ç”Ÿæˆæ–‡æœ¬ã€‚

```python
import openai

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = openai.OpenAI()

# ä½¿ç”¨æœ€æ–°gpt-4oæ¨¡å‹ï¼ˆçº¯æ–‡æœ¬æ¨¡å¼ï¼‰
response = client.chat.completions.create(
    model="gpt-4o",  # æœ€æ–°å¤šæ¨¡æ€æ¨¡å‹ï¼ˆä¹Ÿæ”¯æŒçº¯æ–‡æœ¬ï¼‰
    messages=[
        {"role": "user", "content": "å†™ä¸€é¦–å…³äºç¼–ç¨‹çš„ä¿³å¥ã€‚"}
    ]
)

print(response.choices[0].message.content)
```

### å›¾è¡¨ï¼šAPIè°ƒç”¨æµç¨‹

```mermaid
graph LR
A[è¾“å…¥æç¤º] --> B[APIè°ƒç”¨]
B --> C[æ¨¡å‹å¤„ç†]
C --> D[ç”Ÿæˆè¾“å‡º]
```

## æ¨¡å‹é€‰æ‹©

é€‰æ‹©åˆé€‚çš„æ¨¡å‹æ˜¯ç”Ÿæˆé«˜è´¨é‡æ–‡æœ¬çš„å…³é”®ã€‚ä¸åŒæ¨¡å‹æœ‰ä¸åŒçš„ç‰¹ç‚¹å’Œé€‚ç”¨åœºæ™¯ã€‚æˆ‘ä»¬å°†é€šè¿‡ä¸€ä¸ªå†³ç­–æ ‘å›¾è¡¨æ¥å¸®åŠ©ä½ é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹ã€‚

| æ¨¡å‹ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ | æˆæœ¬ |
|------|------|----------|------|
| gpt-4o-text | çº¯æ–‡æœ¬ä¼˜åŒ– | å¤æ‚æ–‡æœ¬ä»»åŠ¡ | è¾ƒé«˜ |
| gpt-3.5-turbo | æ€§ä»·æ¯”ä¼˜åŒ– | ä¸€èˆ¬ä»»åŠ¡ | é€‚ä¸­ |
| gpt-3.5-16k | æ”¯æŒé•¿æ–‡æœ¬ | é•¿æ–‡å¤„ç† | é€‚ä¸­ |

### å›¾è¡¨ï¼šæ¨¡å‹é€‰æ‹©å†³ç­–æ ‘

```mermaid
graph TD
A[å¼€å§‹] -->|å¤æ‚ä»»åŠ¡| B[gpt-4o]
A -->|é•¿æ–‡æœ¬| C[gpt-3.5-16k]
A -->|ä¸€èˆ¬ä»»åŠ¡| D[gpt-3.5-turbo]
```

## æ„å»ºæç¤ºè¯

æ„å»ºæœ‰æ•ˆçš„æç¤ºè¯å¯ä»¥æ˜¾è‘—æå‡æ–‡æœ¬ç”Ÿæˆçš„æ•ˆæœã€‚åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•é€šè¿‡è®¾å®šè§’è‰²å’Œä½¿ç”¨æ¨¡æ¿æ¥å¼•å¯¼æ¨¡å‹ç”Ÿæˆç¬¦åˆé¢„æœŸçš„æ–‡æœ¬ã€‚

```python
def create_chat(role_description):
    """åˆ›å»ºå¸¦è§’è‰²è®¾å®šçš„å¯¹è¯"""
    messages = [
        {
            "role": "system",
            "content": role_description
        }
    ]
    return messages

# ç¤ºä¾‹ï¼šåˆ›å»ºä¸€ä¸ªæŠ€æœ¯æ–‡æ¡£å†™ä½œåŠ©æ‰‹
messages = create_chat("""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ–‡æ¡£ä½œè€…ï¼Œç‰¹ç‚¹æ˜¯ï¼š
1. ä½¿ç”¨æ¸…æ™°ç®€æ´çš„è¯­è¨€
2. å–„äºä¸¾ä¾‹è¯´æ˜
3. æ³¨é‡å®ç”¨æ€§
4. ç»“æ„å±‚æ¬¡åˆ†æ˜
""")
```

### å›¾è¡¨ï¼šæç¤ºè¯æ¨¡æ¿ç»“æ„

```mermaid
graph LR
E[è§’è‰²è®¾å®š] --> F[æç¤ºè¯æ¨¡æ¿]
F --> G[ç”Ÿæˆæ–‡æœ¬]
```

## å¯¹è¯ç®¡ç†

åœ¨å¤šè½®å¯¹è¯ä¸­ï¼Œç»´æŠ¤ä¸Šä¸‹æ–‡æ˜¯ç¡®ä¿æ¨¡å‹ç”Ÿæˆç›¸å…³ä¸”è¿è´¯å“åº”çš„å…³é”®ã€‚æˆ‘ä»¬å°†ä»‹ç»å¦‚ä½•é€šè¿‡ä¸Šä¸‹æ–‡ç®¡ç†æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚

```python
class ConversationManager:
    def __init__(self):
        self.messages = []
        self.max_tokens = 4000
    
    def add_message(self, role, content):
        """æ·»åŠ æ–°æ¶ˆæ¯"""
        self.messages.append({
            "role": role,
            "content": content
        })
        self._trim_if_needed()
    
    def _trim_if_needed(self):
        """æ§åˆ¶å¯¹è¯é•¿åº¦"""
        while self._estimate_tokens() > self.max_tokens:
            self.messages.pop(1)  # ä¿ç•™systemæ¶ˆæ¯
    
    def _estimate_tokens(self):
        """ä¼°ç®—tokenæ•°é‡"""
        return sum(len(m["content"].split()) * 1.3 for m in self.messages)
```

### å›¾è¡¨ï¼šä¸Šä¸‹æ–‡ç®¡ç†æµç¨‹

```mermaid
graph LR
H[æ–°æ¶ˆæ¯] --> I[æ·»åŠ åˆ°å¯¹è¯]
I --> J{æ˜¯å¦è¶…å‡ºé•¿åº¦}
J -->|æ˜¯| K[ç§»é™¤æ—§æ¶ˆæ¯]
J -->|å¦| L[ç»§ç»­å¯¹è¯]
```

## å®æˆ˜åº”ç”¨

åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†å±•ç¤ºä¸€äº›å®é™…åº”ç”¨çš„ä¾‹å­ï¼ŒåŒ…æ‹¬æ™ºèƒ½å†™ä½œåŠ©æ‰‹ã€å¤šè¯­è¨€ç¿»è¯‘å’Œç»“æ„åŒ–æ•°æ®ç”Ÿæˆã€‚

### æ™ºèƒ½å†™ä½œåŠ©æ‰‹

```python
class WritingAssistant:
    def __init__(self):
        self.client = openai.OpenAI()
        self.conversation = ConversationManager()
    
    def write_article(self, topic, style="ä¸“ä¸š", length=1000):
        """ç”Ÿæˆæ–‡ç« """
        prompt = create_prompt_template("article").format(
            topic=topic,
            style=style,
            length=length,
            audience="ä¸€èˆ¬è¯»è€…",
            key_points="ä¸»è¦æ¦‚å¿µã€åº”ç”¨åœºæ™¯ã€å‘å±•è¶‹åŠ¿"
        )
        
        response = self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡ç« å†™æ‰‹"},
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content
```

### å¤šè¯­è¨€ç¿»è¯‘

```python
def translate_text(text, target_lang="è‹±æ–‡"):
    """å¤šè¯­è¨€ç¿»è¯‘å·¥å…·"""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "system",
                "content": f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘ä¸“å®¶ï¼Œæ“…é•¿å°†ä¸­æ–‡ç¿»è¯‘æˆ{target_lang}"
            },
            {
                "role": "user",
                "content": f"è¯·å°†ä»¥ä¸‹å†…å®¹ç¿»è¯‘æˆ{target_lang}ï¼š\n{text}"
            }
        ]
    )
    return response.choices[0].message.content
```

### ç»“æ„åŒ–æ•°æ®ç”Ÿæˆ

```python
def generate_structured_data(text):
    """ç”ŸæˆJSONæ ¼å¼æ•°æ®"""
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–æ•°æ®"},
            {"role": "user", "content": text}
        ],
        response_format={"type": "json_object"}  # ç»“æ„åŒ–è¾“å‡º
    )
    return response.choices[0].message.content
```

## ä¼˜åŒ–æŠ€å·§

åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸€äº›ä¼˜åŒ–æŠ€å·§ï¼ŒåŒ…æ‹¬å‚æ•°è°ƒä¼˜å’Œé”™è¯¯å¤„ç†ï¼Œä»¥å¸®åŠ©ä½ æ›´å¥½åœ°ä½¿ç”¨æ–‡æœ¬ç”ŸæˆæŠ€æœ¯ã€‚

### å‚æ•°è°ƒä¼˜

```python
def optimize_parameters():
    """ä¸åŒåœºæ™¯çš„å‚æ•°è®¾ç½®"""
    return {
        "temperature": 0.7,  # æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§
        "max_tokens": 150,  # é™åˆ¶ç”Ÿæˆæ–‡æœ¬çš„é•¿åº¦
        "top_p": 0.9,  # ä½¿ç”¨nucleusé‡‡æ ·
        "frequency_penalty": 0,  # æ§åˆ¶é‡å¤å†…å®¹çš„ç”Ÿæˆ
        "presence_penalty": 0  # æ§åˆ¶æ–°ä¸»é¢˜çš„å¼•å…¥
    }
```

### é”™è¯¯å¤„ç†

```python
def safe_generate(prompt):
    """å¸¦é”™è¯¯å¤„ç†çš„ç”Ÿæˆå‡½æ•°"""
    try:
        return client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}]
        )
    except Exception as e:
        return f"APIé”™è¯¯ï¼š{str(e)}"
```

## æœ€ä½³å®è·µ

æœ€åï¼Œæˆ‘ä»¬å°†åˆ†äº«ä¸€äº›æœ€ä½³å®è·µï¼ŒåŒ…æ‹¬å†…å®¹å®‰å…¨å’Œæˆæœ¬æ§åˆ¶ï¼Œä»¥å¸®åŠ©ä½ åœ¨ä½¿ç”¨æ–‡æœ¬ç”ŸæˆæŠ€æœ¯æ—¶æ›´å¥½åœ°ç®¡ç†èµ„æºã€‚

### å†…å®¹å®‰å…¨

```python
def check_content_safety(text):
    """å†…å®¹å®‰å…¨æ£€æŸ¥"""
    response = client.moderations.create(input=text)
    return response.results[0].flagged
```

### æˆæœ¬æ§åˆ¶

```python
def calculate_cost(model, input_tokens, output_tokens):
    """è®¡ç®—ç”Ÿæˆæˆæœ¬"""
    cost_per_token = {
        "gpt-4o": 0.03,
        "gpt-3.5-turbo": 0.02
    }
    in_cost = input_tokens * cost_per_token[model]
    out_cost = output_tokens * cost_per_token[model]
    return round(in_cost + out_cost, 4)
```

## å®è·µç»ƒä¹ 

é€šè¿‡ä»¥ä¸‹ç»ƒä¹ ï¼Œä½ å¯ä»¥å®è·µæ‰€å­¦çš„çŸ¥è¯†ï¼š

1. å®ç°ä¸€ä¸ªå¤šè¯­è¨€ç¿»è¯‘å·¥å…·
2. æ„å»ºå¸¦ä¸Šä¸‹æ–‡è®°å¿†çš„å¯¹è¯ç³»ç»Ÿ
3. å¼€å‘ä¸€ä¸ªè‡ªåŠ¨ç”Ÿæˆå‘¨æŠ¥çš„å·¥å…·
4. åˆ›å»ºå†…å®¹å®‰å…¨æ£€æŸ¥æœºåˆ¶

## ä¸‹ä¸€æ­¥

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å­¦ä¹ ä»£ç ç”Ÿæˆèƒ½åŠ›ï¼Œæ¢ç´¢AIå¦‚ä½•è¾…åŠ©ç¼–ç¨‹ã€‚

ğŸš§ æœ¬èŠ‚å†…å®¹æŒç»­å®Œå–„ä¸­...